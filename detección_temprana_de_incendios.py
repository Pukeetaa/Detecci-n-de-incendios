# -*- coding: utf-8 -*-
"""Detección_Temprana_de_incendios.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_uMUl5glgqqVHpOdqeLbwrKnW2zG5qhH

**DETECCIÓN TEMPRANA DE INCENDIOS**

**OBJETIVO:** desarrollar un sistema de inteligencia artificial capaz de analizar imágenes de satélite con el fin de identificar signos tempranos de fuegos forestales y predecir su comportamiento con el fin de facilitar una respuesta rápida y efectiva ante ellos.

# Preparación del entorno
"""

import os
from PIL import Image
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.metrics import classification_report

import os
import shutil

# Ruta a la carpeta que contiene los datos
data_dir = '/content/drive/MyDrive/mejoras/test'

# Ruta de destino en tu Google Drive
ruta_destino = "/content/drive/My Drive/mejoras/test/"

# Copiar la estructura de la carpeta y sus archivos a Google Drive
shutil.copytree(data_dir, os.path.join(ruta_destino, "carpeta_subida"))


# Nombres de las subcarpetas
subfolders = ['nowildfire', 'wildfire']

# Listas para almacenar imágenes y etiquetas
images_data = []
labels = []

# Procesar cada subcarpeta
for subfolder in subfolders:
    subfolder_path = os.path.join(data_dir, subfolder)
    images = os.listdir(subfolder_path)
    for image_name in images:
        image_path = os.path.join(subfolder_path, image_name)
        try:
            img = Image.open(image_path).convert('RGB')
            img = img.resize((128, 128))
            img_array = np.array(img)
            images_data.append(img_array)
            labels.append(subfolder)
        except Exception as e:
            print(f"Error al procesar la imagen {image_path}: {e}")

# Convertir listas a arrays numpy y normalizar
images_data = np.array(images_data, dtype='float32') / 255.0
labels = np.array(labels)

# Codificar las etiquetas
encoder = LabelEncoder()
labels_encoded = encoder.fit_transform(labels)

# División de los datos
X_train, X_test, y_train, y_test = train_test_split(images_data, labels_encoded, test_size=0.2, random_state=42)

"""# Construcción del modelo

"""

model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

"""# `Visualización de la arquitectura del modelo`"""

# Visualización del modelo
tf.keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

"""# Entrenamiento del modelo"""

history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))

"""# Evaluación del modelo"""

# Evaluación del modelo
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)
print('\nTest accuracy:', test_acc)

# Predicciones
predictions = model.predict(X_test)
predictions_classes = np.round(predictions).flatten()

# Informe de clasificación
print(classification_report(y_test, predictions_classes, target_names=encoder.classes_))

"""# Visualización del rendimiento"""

plt.figure(figsize=(10, 5))

# Precisión
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy Evolution')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Pérdida
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss Evolution')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.show()

"""# Aumento de datos"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Generador de aumento de datos
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    zoom_range=0.2,
    fill_mode='nearest')

# Este generador se usa durante el entrenamiento con model.fit_generator en lugar de model.fit

"""# Implementación de Callbacks"""

from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

# Callback para guardar el modelo con el mejor rendimiento en validación
checkpoint = ModelCheckpoint(
    'mejor_modelo.h5', save_best_only=True, monitor='val_loss', mode='min')

# Callback para detener el entrenamiento si no hay mejora en validación
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Incluir estos callbacks en el método fit
history = model.fit(
    X_train, y_train, epochs=20, validation_data=(X_test, y_test),
    callbacks=[checkpoint, early_stop])

"""# Evaluación Detallada del Modelo"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Generar la matriz de confusión
conf_matrix = confusion_matrix(y_test, predictions_classes)

# Visualización de la matriz de confusión
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

"""# Demostración del Modelo"""

import matplotlib.pyplot as plt

def mostrar_predicciones(X, y, predictions, n=10):
    indices = np.random.choice(range(len(X)), n, replace=False)
    for i in indices:
        img = X[i]
        actual = y[i]
        pred = predictions[i]
        plt.figure(figsize=(2, 2))
        plt.imshow(img)
        plt.title(f'Actual: {encoder.classes_[actual]}, Predicted: {encoder.classes_[int(pred)]}')
        plt.axis('off')
        plt.show()

# Llamada a la función para mostrar predicciones
mostrar_predicciones(X_test, y_test, predictions_classes)

from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt

def predict_fire(image_path, model):
    """
    Función para predecir si hay fuego en una imagen.

    Parameters:
    - image_path: Ruta a la imagen que se va a predecir.
    - model: Modelo entrenado para predecir la presencia de fuego.

    Returns:
    - None: Solo muestra en pantalla la predicción.
    """
    # Cargar la imagen
    img = image.load_img(image_path, target_size=(128, 128))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0

    # Realizar la predicción
    predictions = model.predict(img_array)

    # Mostrar la imagen
    plt.imshow(img)
    plt.axis('off')

    # Interpretar la predicción
    if predictions[0] > 0.5:
        plt.title(f"{predictions[0][0]*100:.2f}% seguro de que hay fuego.")
    else:
        plt.title(f"{(1-predictions[0][0])*100:.2f}% seguro de que no hay fuego.")
    plt.show()

# Ejemplo de uso
image_path = '/content/drive/MyDrive/mejoras/test/wildfire/-60.73875,50.24761.jpg'
predict_fire(image_path, model)

# Ejemplo 2 de uso
image_path = '/content/drive/MyDrive/mejoras/test/nowildfire/-73.6637,45.419342.jpg'
predict_fire(image_path, model)

# Ejemplo 3 de uso con humo
image_path = '/content/drive/MyDrive/mejoras/test/wildfire/-71.61443,50.43285.jpg'
predict_fire(image_path, model)

"""# Curva ROC"""

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Obtener las probabilidades de predicción en lugar de las clases predichas
y_scores = model.predict(X_test)

# Calcular la curva ROC
fpr, tpr, thresholds = roc_curve(y_test, y_scores)

# Calcular el área bajo la curva (AUC)
roc_auc = auc(fpr, tpr)

# Plotear la curva ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()